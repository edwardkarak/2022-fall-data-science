{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise with Natural Language Processing\n",
    "\n",
    "For todays exersice we will be doing two things.  The first is to build the same model with the same data that we did in the lecture, the second will be to build a new model with new data. \n",
    "\n",
    "## PART 1: \n",
    "- 20 Newsgroups Corpus\n",
    "\n",
    "\n",
    "## PART 2:\n",
    "- Republican vs Democrat Tweet Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\Edward\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\Edward\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\Edward\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "# Import pandas for data handling\n",
    "import pandas as pd\n",
    "\n",
    "# NLTK is our Natural-Language-Took-Kit\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk import word_tokenize\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.corpus import wordnet\n",
    "\n",
    "# Libraries for helping us with strings\n",
    "import string\n",
    "# Regular Expression Library\n",
    "import re\n",
    "\n",
    "# Import our text vectorizers\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "\n",
    "# Import our classifiers\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "\n",
    "# Import some ML helper function\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import plot_confusion_matrix\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "\n",
    "# Import our metrics to evaluate our model\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "\n",
    "# Library for plotting\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# You may need to download these from nltk\n",
    "nltk.download('stopwords')\n",
    "nltk.download('punkt')\n",
    "nltk.download('wordnet')\n",
    "stopwords = stopwords.words('english')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load and display data.\n",
    "1. Load the 20-newsgroups.csv data into a dataframe.\n",
    "1. Print the shape\n",
    "1. Inspect / remove nulls and duplicates\n",
    "1. Find class balances, print out how many of each topic_category there are."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>message</th>\n",
       "      <th>topic</th>\n",
       "      <th>topic_category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>From: lerxst@wam.umd.edu (where's my thing)\\r\\...</td>\n",
       "      <td>7</td>\n",
       "      <td>rec.autos</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>From: guykuo@carson.u.washington.edu (Guy Kuo)...</td>\n",
       "      <td>4</td>\n",
       "      <td>comp.sys.mac.hardware</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>From: twillis@ec.ecn.purdue.edu (Thomas E Will...</td>\n",
       "      <td>4</td>\n",
       "      <td>comp.sys.mac.hardware</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>From: jgreen@amber (Joe Green)\\r\\nSubject: Re:...</td>\n",
       "      <td>1</td>\n",
       "      <td>comp.graphics</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>From: jcm@head-cfa.harvard.edu (Jonathan McDow...</td>\n",
       "      <td>14</td>\n",
       "      <td>sci.space</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id                                            message  topic  \\\n",
       "0   0  From: lerxst@wam.umd.edu (where's my thing)\\r\\...      7   \n",
       "1   1  From: guykuo@carson.u.washington.edu (Guy Kuo)...      4   \n",
       "2   2  From: twillis@ec.ecn.purdue.edu (Thomas E Will...      4   \n",
       "3   3  From: jgreen@amber (Joe Green)\\r\\nSubject: Re:...      1   \n",
       "4   4  From: jcm@head-cfa.harvard.edu (Jonathan McDow...     14   \n",
       "\n",
       "          topic_category  \n",
       "0              rec.autos  \n",
       "1  comp.sys.mac.hardware  \n",
       "2  comp.sys.mac.hardware  \n",
       "3          comp.graphics  \n",
       "4              sci.space  "
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 1. Load the 20-newsgroups.csv data into a dataframe.\n",
    "# 2. Print the shape\n",
    "df = pd.read_csv('data/20-newsgroups.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "id                0\n",
       "message           0\n",
       "topic             0\n",
       "topic_category    0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 3. Inspect / remove nulls and duplicates\n",
    "df.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 4. Find class balances, print out how many of each topic_category there are.\n",
    "df.duplicated().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Text Pre-Processing \n",
    "(aka Feature engineering)\n",
    "1. Make a function that makes all text lowercase.\n",
    "    * Do a sanity check by feeding in a test sentence into the function. \n",
    "    \n",
    "    \n",
    "2. Make a function that removes all punctuation. \n",
    "    * Do a sanity check by feeding in a test sentence into the function. \n",
    "    \n",
    "    \n",
    "3. Make a function that removes all stopwords.\n",
    "    * Do a sanity check by feeding in a test sentence into the function. \n",
    "    \n",
    "    \n",
    "4. EXTRA CREDIT (This step only): Make a function that stemms all words. \n",
    "\n",
    "\n",
    "5. Mandatory: Make a pipeline function that applys all the text processing functions you just built.\n",
    "    * Do a sanity check by feeding in a test sentence into the pipeline. \n",
    "    \n",
    "    \n",
    "    \n",
    "6. Mandatory: Use `df['message_clean'] = df[column].apply(???)` and apply the text pipeline to your text data column. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'this is a sentence with lots of caps.'"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 1. Make a function that makes all text lowercase.\n",
    "\n",
    "test_string = 'This is A SENTENCE with LOTS OF CAPS.'\n",
    "def allLower(s):\n",
    "    return s.lower()\n",
    "allLower(test_string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is a sentence 50 With lots of punctuation  other things\n"
     ]
    }
   ],
   "source": [
    "# 2. Make a function that removes all punctuation.\n",
    "\n",
    "test_string = 'This is a sentence! 50 With lots of punctuation??? & other #things.'\n",
    "def remPunct(s):\n",
    "    for c in string.punctuation:\n",
    "        s = s.replace(c, \"\")\n",
    "    return s\n",
    "\n",
    "print(remPunct(test_string))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'This sentence ! With different stopwords added .'"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 3. Make a function that removes all stopwords.\n",
    "\n",
    "test_string = 'This is a sentence! With some different stopwords i have added in here.'\n",
    "def remStop(s):\n",
    "    words = word_tokenize(s)    \n",
    "    valid = []\n",
    "    for w in words:\n",
    "        if w not in stopwords:\n",
    "            valid.append(w)\n",
    "    \n",
    "    return ' '.join(valid)\n",
    "    \n",
    "remStop(test_string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'I play and start play with player and we all love to play with play'"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 4. EXTRA CREDIT: Make a function that stemms all words. \n",
    "\n",
    "test_string = 'I played and started playing with players and we all love to play with plays'\n",
    "def stem(s):\n",
    "    porter = PorterStemmer()\n",
    "    words = word_tokenize(s)\n",
    "    \n",
    "    valid = []\n",
    "\n",
    "    # Loop through all the words\n",
    "    for w in words:\n",
    "        # Stem the word\n",
    "        stemmed_word = porter.stem(w)\n",
    "        \n",
    "        # Append stemmed word to our valid_words\n",
    "        valid.append(stemmed_word)\n",
    "        \n",
    "    # Join the list of words together into a string\n",
    "    return ' '.join(valid)\n",
    "stem(test_string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'play start play player love play play'"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 5. MANDATORY: Make a pipeline function that applys all the text processing functions you just built.\n",
    "\n",
    "test_string = 'I played and started playing with players and we all love to play with plays'\n",
    "def pipe(s):\n",
    "    return stem(remStop(remPunct(allLower(s))))\n",
    "pipe(test_string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 6. Mandatory: Use `df[column].apply(???)` and apply the text pipeline to your text data column. \n",
    "df['message_clean'] = df['message'].apply(pipe)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Text Vectorization\n",
    "\n",
    "1. Define your `X` and `y` data. \n",
    "\n",
    "\n",
    "2. Initialize a vectorizer (you can use TFIDF or BOW, it is your choice).\n",
    "    * Do you want to use n-grams..?\n",
    "\n",
    "\n",
    "3. Fit your vectorizer using your X data.\n",
    "    * Remember, this process happens IN PLACE.\n",
    "\n",
    "\n",
    "4. Transform your X data using your fitted vectorizer. \n",
    "    * `X = vectorizer.???`\n",
    "\n",
    "\n",
    "\n",
    "5. Print the shape of your X.  How many features (aka columns) do you have?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Define your `X` and `y` data. \n",
    "\n",
    "X = df.message_clean.values\n",
    "y = df.topic_category.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Initialize a vectorizer (you can use TFIDF or BOW, it is your choice).\n",
    "\n",
    "vectorizer = TfidfVectorizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "lower not found",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-91-d5f341cf9086>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# 3. Fit your vectorizer using your X data\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mvectorizer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\feature_extraction\\text.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, raw_documents, y)\u001b[0m\n\u001b[0;32m   1815\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_check_params\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1816\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_warn_for_unused_params\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1817\u001b[1;33m         \u001b[0mX\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msuper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit_transform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mraw_documents\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1818\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_tfidf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1819\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\feature_extraction\\text.py\u001b[0m in \u001b[0;36mfit_transform\u001b[1;34m(self, raw_documents, y)\u001b[0m\n\u001b[0;32m   1196\u001b[0m         \u001b[0mmax_features\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmax_features\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1197\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1198\u001b[1;33m         vocabulary, X = self._count_vocab(raw_documents,\n\u001b[0m\u001b[0;32m   1199\u001b[0m                                           self.fixed_vocabulary_)\n\u001b[0;32m   1200\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\feature_extraction\\text.py\u001b[0m in \u001b[0;36m_count_vocab\u001b[1;34m(self, raw_documents, fixed_vocab)\u001b[0m\n\u001b[0;32m   1108\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mdoc\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mraw_documents\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1109\u001b[0m             \u001b[0mfeature_counter\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m{\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1110\u001b[1;33m             \u001b[1;32mfor\u001b[0m \u001b[0mfeature\u001b[0m \u001b[1;32min\u001b[0m \u001b[0manalyze\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdoc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1111\u001b[0m                 \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1112\u001b[0m                     \u001b[0mfeature_idx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mvocabulary\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mfeature\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\feature_extraction\\text.py\u001b[0m in \u001b[0;36m_analyze\u001b[1;34m(doc, analyzer, tokenizer, ngrams, preprocessor, decoder, stop_words)\u001b[0m\n\u001b[0;32m    102\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    103\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mpreprocessor\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 104\u001b[1;33m             \u001b[0mdoc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpreprocessor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdoc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    105\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mtokenizer\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    106\u001b[0m             \u001b[0mdoc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtokenizer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdoc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\feature_extraction\\text.py\u001b[0m in \u001b[0;36m_preprocess\u001b[1;34m(doc, accent_function, lower)\u001b[0m\n\u001b[0;32m     67\u001b[0m     \"\"\"\n\u001b[0;32m     68\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mlower\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 69\u001b[1;33m         \u001b[0mdoc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdoc\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlower\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     70\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0maccent_function\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     71\u001b[0m         \u001b[0mdoc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0maccent_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdoc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\scipy\\sparse\\base.py\u001b[0m in \u001b[0;36m__getattr__\u001b[1;34m(self, attr)\u001b[0m\n\u001b[0;32m    685\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgetnnz\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    686\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 687\u001b[1;33m             \u001b[1;32mraise\u001b[0m \u001b[0mAttributeError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mattr\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m\" not found\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    688\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    689\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mtranspose\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxes\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: lower not found"
     ]
    }
   ],
   "source": [
    "# 3. Fit your vectorizer using your X data\n",
    "\n",
    "vectorizer.fit(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "lower not found",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-90-f2cd7376b708>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# 4. Transform your X data using your fitted vectorizer.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mX\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mvectorizer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\feature_extraction\\text.py\u001b[0m in \u001b[0;36mtransform\u001b[1;34m(self, raw_documents, copy)\u001b[0m\n\u001b[0;32m   1877\u001b[0m                    \"be removed in 0.24.\")\n\u001b[0;32m   1878\u001b[0m             \u001b[0mwarnings\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwarn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mFutureWarning\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1879\u001b[1;33m         \u001b[0mX\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msuper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mraw_documents\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1880\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_tfidf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1881\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\feature_extraction\\text.py\u001b[0m in \u001b[0;36mtransform\u001b[1;34m(self, raw_documents)\u001b[0m\n\u001b[0;32m   1247\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1248\u001b[0m         \u001b[1;31m# use the same matrix-building strategy as fit_transform\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1249\u001b[1;33m         \u001b[0m_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_count_vocab\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mraw_documents\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfixed_vocab\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1250\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbinary\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1251\u001b[0m             \u001b[0mX\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfill\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\feature_extraction\\text.py\u001b[0m in \u001b[0;36m_count_vocab\u001b[1;34m(self, raw_documents, fixed_vocab)\u001b[0m\n\u001b[0;32m   1108\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mdoc\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mraw_documents\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1109\u001b[0m             \u001b[0mfeature_counter\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m{\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1110\u001b[1;33m             \u001b[1;32mfor\u001b[0m \u001b[0mfeature\u001b[0m \u001b[1;32min\u001b[0m \u001b[0manalyze\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdoc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1111\u001b[0m                 \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1112\u001b[0m                     \u001b[0mfeature_idx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mvocabulary\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mfeature\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\feature_extraction\\text.py\u001b[0m in \u001b[0;36m_analyze\u001b[1;34m(doc, analyzer, tokenizer, ngrams, preprocessor, decoder, stop_words)\u001b[0m\n\u001b[0;32m    102\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    103\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mpreprocessor\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 104\u001b[1;33m             \u001b[0mdoc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpreprocessor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdoc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    105\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mtokenizer\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    106\u001b[0m             \u001b[0mdoc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtokenizer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdoc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\feature_extraction\\text.py\u001b[0m in \u001b[0;36m_preprocess\u001b[1;34m(doc, accent_function, lower)\u001b[0m\n\u001b[0;32m     67\u001b[0m     \"\"\"\n\u001b[0;32m     68\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mlower\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 69\u001b[1;33m         \u001b[0mdoc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdoc\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlower\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     70\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0maccent_function\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     71\u001b[0m         \u001b[0mdoc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0maccent_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdoc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\scipy\\sparse\\base.py\u001b[0m in \u001b[0;36m__getattr__\u001b[1;34m(self, attr)\u001b[0m\n\u001b[0;32m    685\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgetnnz\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    686\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 687\u001b[1;33m             \u001b[1;32mraise\u001b[0m \u001b[0mAttributeError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mattr\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m\" not found\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    688\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    689\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mtranspose\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxes\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: lower not found"
     ]
    }
   ],
   "source": [
    "# 4. Transform your X data using your fitted vectorizer. \n",
    "\n",
    "X = vectorizer.transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(11314, 118520) <class 'scipy.sparse.csr.csr_matrix'>\n"
     ]
    }
   ],
   "source": [
    "# 5. Print the shape of your X.  How many features (aka columns) do you have?\n",
    "print(X.shape, type(X))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Split your data into Training and Testing data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split our data into testing and training like always. \n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "# Build and Train Model\n",
    "Use Multinomial Naive Bayes to classify these documents. \n",
    "\n",
    "1. Initalize an empty model. \n",
    "2. Fit the model with our training data.\n",
    "\n",
    "\n",
    "Experiment with different alphas.  Use the alpha gives you the best result.\n",
    "\n",
    "EXTRA CREDIT:  Use grid search to programmatically do this for you. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Initalize an empty model. \n",
    "\n",
    "model = MultinomialNB(alpha=.05)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "could not convert string to float: 'rupindangdartmouthedu rupin dang subject nikon fm2 len forsal organ dartmouth colleg hanov nh line 5 nikon fm2n 50 mm nikkor accessori salei bought camera hong kong two year ago everyth look well im sell gear financ next big film project ask 350 packag bargain'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-97-6d5d033d524c>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# Fit our model with our training data.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\naive_bayes.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[0;32m    613\u001b[0m         \u001b[0mself\u001b[0m \u001b[1;33m:\u001b[0m \u001b[0mobject\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    614\u001b[0m         \"\"\"\n\u001b[1;32m--> 615\u001b[1;33m         \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_check_X_y\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    616\u001b[0m         \u001b[0m_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_features\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    617\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mn_features_\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mn_features\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\naive_bayes.py\u001b[0m in \u001b[0;36m_check_X_y\u001b[1;34m(self, X, y)\u001b[0m\n\u001b[0;32m    478\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    479\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_check_X_y\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 480\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_validate_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maccept_sparse\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'csr'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    481\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    482\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m_update_class_log_prior\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mclass_prior\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\base.py\u001b[0m in \u001b[0;36m_validate_data\u001b[1;34m(self, X, y, reset, validate_separately, **check_params)\u001b[0m\n\u001b[0;32m    430\u001b[0m                 \u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mcheck_y_params\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    431\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 432\u001b[1;33m                 \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcheck_X_y\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mcheck_params\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    433\u001b[0m             \u001b[0mout\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    434\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36minner_f\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     71\u001b[0m                           FutureWarning)\n\u001b[0;32m     72\u001b[0m         \u001b[0mkwargs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m{\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0marg\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0marg\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msig\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 73\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     74\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0minner_f\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     75\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36mcheck_X_y\u001b[1;34m(X, y, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, multi_output, ensure_min_samples, ensure_min_features, y_numeric, estimator)\u001b[0m\n\u001b[0;32m    794\u001b[0m         \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"y cannot be None\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    795\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 796\u001b[1;33m     X = check_array(X, accept_sparse=accept_sparse,\n\u001b[0m\u001b[0;32m    797\u001b[0m                     \u001b[0maccept_large_sparse\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0maccept_large_sparse\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    798\u001b[0m                     \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0morder\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0morder\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcopy\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36minner_f\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     71\u001b[0m                           FutureWarning)\n\u001b[0;32m     72\u001b[0m         \u001b[0mkwargs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m{\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0marg\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mk\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0marg\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msig\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 73\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     74\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0minner_f\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     75\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py\u001b[0m in \u001b[0;36mcheck_array\u001b[1;34m(array, accept_sparse, accept_large_sparse, dtype, order, copy, force_all_finite, ensure_2d, allow_nd, ensure_min_samples, ensure_min_features, estimator)\u001b[0m\n\u001b[0;32m    597\u001b[0m                     \u001b[0marray\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0marray\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mastype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcasting\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m\"unsafe\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    598\u001b[0m                 \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 599\u001b[1;33m                     \u001b[0marray\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0morder\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0morder\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    600\u001b[0m             \u001b[1;32mexcept\u001b[0m \u001b[0mComplexWarning\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    601\u001b[0m                 raise ValueError(\"Complex data not supported\\n\"\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\numpy\\core\\_asarray.py\u001b[0m in \u001b[0;36masarray\u001b[1;34m(a, dtype, order)\u001b[0m\n\u001b[0;32m     83\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     84\u001b[0m     \"\"\"\n\u001b[1;32m---> 85\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0morder\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0morder\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     86\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     87\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: could not convert string to float: 'rupindangdartmouthedu rupin dang subject nikon fm2 len forsal organ dartmouth colleg hanov nh line 5 nikon fm2n 50 mm nikkor accessori salei bought camera hong kong two year ago everyth look well im sell gear financ next big film project ask 350 packag bargain'"
     ]
    }
   ],
   "source": [
    "# Fit our model with our training data.\n",
    "model.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluate the model.\n",
    "\n",
    "1. Make new predicitions using our test data. \n",
    "2. Print the accuracy of the model. \n",
    "3. Print the confusion matrix of our predictions. \n",
    "4. Using `classification_report` print the evaluation results for all the classes. \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Make new predictions of our testing data. \n",
    "\n",
    "y_pred = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2. Print the accuracy of the model. \n",
    "accuracy = model.score(X_test, y_test)\n",
    "\n",
    "print(\"Model Accuracy: %f\" % accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'MultinomialNB' object has no attribute 'classes_'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-99-51430a7f134b>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m disp = plot_confusion_matrix(model, X_test, y_test,\n\u001b[1;32m----> 6\u001b[1;33m                              \u001b[0mdisplay_labels\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclasses_\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      7\u001b[0m                              cmap=plt.cm.Blues, ax=ax)\n\u001b[0;32m      8\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mxticks\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrotation\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m90\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'MultinomialNB' object has no attribute 'classes_'"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1512x1512 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 3. Plot the confusion matrix of our predictions\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(21, 21))\n",
    "\n",
    "disp = plot_confusion_matrix(model, X_test, y_test,\n",
    "                             display_labels=model.classes_,\n",
    "                             cmap=plt.cm.Blues, ax=ax)\n",
    "plt.xticks(rotation=90)\n",
    "disp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'y_pred' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-101-a53c0251294e>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# 4. Using `classification_report` print the evaluation results for all the classes.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mclassification_report\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget_names\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mclasses_\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'y_pred' is not defined"
     ]
    }
   ],
   "source": [
    "# 4. Using `classification_report` print the evaluation results for all the classes. \n",
    "\n",
    "classification_report(y_test, y_pred, target_names=model.classes_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Manual predicition\n",
    "Write a new sentence that you think will be classified as talk.politics.guns. \n",
    "1. Apply the text pipeline to your sentence\n",
    "2. Transform your cleaned text using the `X = vectorizer.transform([your_text])`\n",
    "    * Note, the `transform` function accepts a list and not a individual string.\n",
    "3. Use the model to predict your new `X`. \n",
    "4. Print the prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'cleaned_text' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-102-51adb746fec6>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mmy_sentence\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m\"Gun ownership should be restricted\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mclean\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpipe\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmy_sentence\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mX\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mvectorizer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtransform\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mcleaned_text\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;31m# 1. Apply the text pipeline to your sentence\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'cleaned_text' is not defined"
     ]
    }
   ],
   "source": [
    "my_sentence = \"Gun ownership should be restricted\"\n",
    "clean = pipe(my_sentence)\n",
    "X = vectorizer.transform([cleaned_text])\n",
    "model.predict(X)\n",
    "# 1. Apply the text pipeline to your sentence\n",
    "\n",
    "# 2. Transform your cleaned text using the `X = vectorizer.transform([your_text])`\\\n",
    "\n",
    "# 3. Use the model to predict your new `X`. \n",
    "\n",
    "# 4. Print the prediction\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "___\n",
    "# PART 2: Twitter Data\n",
    "This part of the exercise is un-guided on purpose.  \n",
    "\n",
    "Using the `dem-vs-rep-tweets.csv` build a classifier to determine if a tweet was written by a democrat or republican. \n",
    "\n",
    "Can you get an f1-score higher than %82"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Party</th>\n",
       "      <th>Handle</th>\n",
       "      <th>Tweet</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Democrat</td>\n",
       "      <td>RepDarrenSoto</td>\n",
       "      <td>Today, Senate Dems vote to #SaveTheInternet. P...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Democrat</td>\n",
       "      <td>RepDarrenSoto</td>\n",
       "      <td>RT @WinterHavenSun: Winter Haven resident / Al...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Democrat</td>\n",
       "      <td>RepDarrenSoto</td>\n",
       "      <td>RT @NBCLatino: .@RepDarrenSoto noted that Hurr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Democrat</td>\n",
       "      <td>RepDarrenSoto</td>\n",
       "      <td>RT @NALCABPolicy: Meeting with @RepDarrenSoto ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Democrat</td>\n",
       "      <td>RepDarrenSoto</td>\n",
       "      <td>RT @Vegalteno: Hurricane season starts on June...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Party         Handle                                              Tweet\n",
       "0  Democrat  RepDarrenSoto  Today, Senate Dems vote to #SaveTheInternet. P...\n",
       "1  Democrat  RepDarrenSoto  RT @WinterHavenSun: Winter Haven resident / Al...\n",
       "2  Democrat  RepDarrenSoto  RT @NBCLatino: .@RepDarrenSoto noted that Hurr...\n",
       "3  Democrat  RepDarrenSoto  RT @NALCABPolicy: Meeting with @RepDarrenSoto ...\n",
       "4  Democrat  RepDarrenSoto  RT @Vegalteno: Hurricane season starts on June..."
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 1. Load the 20-newsgroups.csv data into a dataframe.\n",
    "# 2. Print the shape\n",
    "df = pd.read_csv('data/dem-vs-rep-tweets.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Party     0\n",
      "Handle    0\n",
      "Tweet     0\n",
      "dtype: int64 57\n"
     ]
    }
   ],
   "source": [
    "print(df.isnull().sum(), df.duplicated().sum())"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
